{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0      1  2  3      4     5      6\n",
       "0  vhigh  vhigh  2  2  small   low  unacc\n",
       "1  vhigh  vhigh  2  2  small   med  unacc\n",
       "2  vhigh  vhigh  2  2  small  high  unacc\n",
       "3  vhigh  vhigh  2  2    med   low  unacc\n",
       "4  vhigh  vhigh  2  2    med   med  unacc"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading dataset\n",
    "cars_data=pd.read_csv(r'D:\\Others\\Downloads\\\\cars.csv',header=None)\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1728, 7)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.shape     #gives the no of (rows,columns) in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>buying</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_boot</th>\n",
       "      <th>safety</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  buying  maint doors persons lug_boot safety classes\n",
       "0  vhigh  vhigh     2       2    small    low   unacc\n",
       "1  vhigh  vhigh     2       2    small    med   unacc\n",
       "2  vhigh  vhigh     2       2    small   high   unacc\n",
       "3  vhigh  vhigh     2       2      med    low   unacc\n",
       "4  vhigh  vhigh     2       2      med    med   unacc"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.columns=['buying','maint','doors','persons','lug_boot','safety','classes']  #changing the column names in the data\n",
    "cars_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unacc    1210\n",
       "acc       384\n",
       "good       69\n",
       "vgood      65\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.classes.value_counts()       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "buying      0\n",
       "maint       0\n",
       "doors       0\n",
       "persons     0\n",
       "lug_boot    0\n",
       "safety      0\n",
       "classes     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cars_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars_df=pd.DataFrame.copy(cars_data)      #creating a copy of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['buying', 'maint', 'doors', 'persons', 'lug_boot', 'safety', 'classes'], dtype='object')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colname=cars_df.columns\n",
    "colname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "le={}\n",
    "\n",
    "for x in colname:\n",
    "    le[x]=preprocessing.LabelEncoder()\n",
    "    \n",
    "for x in colname:\n",
    "    cars_df[x]=le[x].fit_transform(cars_df[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cars_df.values[:,:-1]\n",
    "Y=cars_df.values[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:595: DataConversionWarning: Data with input dtype int32 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "#use \"fit\" only on training data and not on testing data\n",
    "#\"transform\" should be applied to both training and testing data\n",
    "\n",
    "scaler=StandardScaler()\n",
    "\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#split the data into train and test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X,Y,test_size=0.3,random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=10,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_DecisionTree=DecisionTreeClassifier(criterion='gini',random_state=10)\n",
    "\n",
    "model_DecisionTree.fit(X_train,Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('buying', 0.1510848831946676), ('maint', 0.2506508516803624), ('doors', 0.060026331736828115), ('persons', 0.19355707150872045), ('lug_boot', 0.09892620952419463), ('safety', 0.2457546523552268)]\n"
     ]
    }
   ],
   "source": [
    "print(list(zip(colname,model_DecisionTree.feature_importances_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 2 2 2 1 2 0 0 2 0 2 2 2 2 0 0 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 0 2 2 2\n",
      " 2 2 0 2 2 2 3 2 0 2 2 2 2 2 0 1 3 1 2 0 2 0 2 2 2 2 3 2 2 0 0 2 2 3 2 2 2\n",
      " 1 2 0 0 2 2 2 2 2 2 2 2 2 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 2 2 2 2\n",
      " 2 2 2 0 2 2 1 2 2 2 2 2 2 0 2 2 2 2 2 2 2 2 2 0 2 2 3 2 2 0 2 0 3 2 2 2 2\n",
      " 2 2 2 2 3 2 2 2 2 2 1 1 2 0 2 2 2 2 2 2 2 2 2 1 2 3 2 2 2 2 0 0 2 2 2 2 3\n",
      " 2 0 2 1 0 2 2 2 2 0 3 0 0 2 2 2 2 0 2 2 2 2 2 2 2 3 0 2 2 2 3 2 2 1 2 2 2\n",
      " 2 2 2 2 0 2 2 2 2 2 0 0 2 2 2 2 3 2 2 0 2 0 2 0 2 2 2 2 2 0 2 2 2 0 2 2 0\n",
      " 2 2 2 0 2 2 2 0 2 2 0 2 2 2 1 1 2 2 2 0 2 2 0 3 3 0 2 0 2 2 2 3 2 2 0 2 2\n",
      " 2 2 2 0 2 2 2 3 2 2 2 0 2 2 2 2 0 0 2 2 1 2 2 2 0 2 2 0 0 2 0 0 2 2 0 0 2\n",
      " 2 2 2 2 0 2 2 2 0 2 2 2 2 2 2 2 2 1 3 3 2 2 2 2 0 2 2 2 3 2 2 0 2 1 2 2 2\n",
      " 0 0 2 2 2 2 2 2 2 0 2 0 1 2 2 2 2 2 0 2 2 3 0 0 0 0 2 0 2 2 2 0 0 2 0 2 1\n",
      " 0 2 2 0 2 2 2 0 1 2 0 0 2 0 2 2 2 2 2 2 2 2 2 2 2 2 0 2 2 3 2 2 2 2 0 2 2\n",
      " 2 0 2 2 2 0 2 2 2 0 2 2 0 3 2 2 2 2 0 2 2 2 2 2 2 0 2 0 2 0 2 2 2 2 0 2 2\n",
      " 2 2 2 2 2 2 2 1 2 2 2 2 2 0 0 2 2 2 0 2 2 2 2 2 0 2 0 2 2 0 2 0 2 2 2 3 2\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "Y_pred=model_DecisionTree.predict(X_test)\n",
    "print(Y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[101   0   1   0]\n",
      " [  2  19   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "0.9922928709055877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98       102\n",
      "           1       1.00      0.90      0.95        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       519\n",
      "   macro avg       0.99      0.96      0.98       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "with open(r'D:\\Others\\Downloads\\carsmodel_DecisionTree.txt', \"w\") as f:\n",
    "    f = tree.export_graphviz(model_DecisionTree, \n",
    "                        feature_names=cars_df.columns[:-1],out_file=f)\n",
    "\n",
    "#generate the file and upload the code in webgraphviz.com to plot the decision tree\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "#create a model\n",
    "classifier=(LogisticRegression())\n",
    "#fitting training data to the model\n",
    "classifier.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=classifier.predict(X_test)\n",
    "#print(list(zip(Y_test,Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22   0  80   0]\n",
      " [  3   0  18   0]\n",
      " [ 30   0 341   0]\n",
      " [ 11   0  14   0]]\n",
      "0.6994219653179191\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.22      0.26       102\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.75      0.92      0.83       371\n",
      "           3       0.00      0.00      0.00        25\n",
      "\n",
      "   micro avg       0.70      0.70      0.70       519\n",
      "   macro avg       0.27      0.28      0.27       519\n",
      "weighted avg       0.60      0.70      0.64       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 82   0  20   0]\n",
      " [ 21   0   0   0]\n",
      " [ 17   0 354   0]\n",
      " [ 17   0   0   8]]\n",
      "0.8554913294797688\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.80      0.69       102\n",
      "           1       0.00      0.00      0.00        21\n",
      "           2       0.95      0.95      0.95       371\n",
      "           3       1.00      0.32      0.48        25\n",
      "\n",
      "   micro avg       0.86      0.86      0.86       519\n",
      "   macro avg       0.64      0.52      0.53       519\n",
      "weighted avg       0.84      0.86      0.84       519\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "#SVM Classifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model=SVC(kernel=\"rbf\", C=1,gamma=0.1)\n",
    "svc_model.fit(X_train, Y_train)\n",
    "Y_pred=svc_model.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Bagging_Classifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier       \n",
    "\n",
    "model=(ExtraTreesClassifier(21))             #creates 21 bags of samples/ implements 21 decision trees (default is 10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 95   4   3   0]\n",
      " [  4  16   0   1]\n",
      " [  1   0 370   0]\n",
      " [  6   0   0  19]]\n",
      "0.9633911368015414\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.93      0.91       102\n",
      "           1       0.80      0.76      0.78        21\n",
      "           2       0.99      1.00      0.99       371\n",
      "           3       0.95      0.76      0.84        25\n",
      "\n",
      "   micro avg       0.96      0.96      0.96       519\n",
      "   macro avg       0.91      0.86      0.88       519\n",
      "weighted avg       0.96      0.96      0.96       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Bagging_Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier       \n",
    "\n",
    "model=(RandomForestClassifier(70))             #creates 21 bags of samples/ implements 21 decision trees (default is 10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 98   3   0   1]\n",
      " [  2  18   0   1]\n",
      " [  2   0 369   0]\n",
      " [  1   0   0  24]]\n",
      "0.9807321772639692\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.96      0.96       102\n",
      "           1       0.86      0.86      0.86        21\n",
      "           2       1.00      0.99      1.00       371\n",
      "           3       0.92      0.96      0.94        25\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       519\n",
      "   macro avg       0.93      0.94      0.94       519\n",
      "weighted avg       0.98      0.98      0.98       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Bagging_Classifier\n",
    "from sklearn.ensemble import AdaBoostClassifier       \n",
    "\n",
    "model=AdaBoostClassifier(base_estimator=DecisionTreeClassifier())             #creates 10 bags of samples/ implements 21 decision trees (default is 10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   1   1   0]\n",
      " [  3  18   0   0]\n",
      " [  0   0 371   0]\n",
      " [  1   0   0  24]]\n",
      "0.9884393063583815\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       102\n",
      "           1       0.95      0.86      0.90        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       1.00      0.96      0.98        25\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       519\n",
      "   macro avg       0.98      0.95      0.96       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting using the Bagging_Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier       \n",
    "\n",
    "model=GradientBoostingClassifier()             #creates 10 bags of samples/ implements 21 decision trees (default is 10)\n",
    "#fit the model on the data and predict the values\n",
    "model=model.fit(X_train,Y_train)\n",
    "\n",
    "Y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[100   2   0   0]\n",
      " [  0  19   0   2]\n",
      " [  0   0 371   0]\n",
      " [  0   0   0  25]]\n",
      "0.9922928709055877\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99       102\n",
      "           1       0.90      0.90      0.90        21\n",
      "           2       1.00      1.00      1.00       371\n",
      "           3       0.93      1.00      0.96        25\n",
      "\n",
      "   micro avg       0.99      0.99      0.99       519\n",
      "   macro avg       0.96      0.97      0.96       519\n",
      "weighted avg       0.99      0.99      0.99       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\Users\\Prakruti Joshi\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#importing packages\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    " \n",
    "\n",
    "# create the sub models\n",
    "estimators = []\n",
    "model1 = LogisticRegression()\n",
    "estimators.append(('log', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "estimators.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "estimators.append(('svm', model3))\n",
    "\n",
    "# create the ensemble model\n",
    "ensemble = VotingClassifier(estimators)\n",
    "ensemble.fit(X_train,Y_train)\n",
    "Y_pred=ensemble.predict(X_test)\n",
    "#print(Y_pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 89   0  13   0]\n",
      " [ 19   2   0   0]\n",
      " [  4   0 367   0]\n",
      " [  5   0   0  20]]\n",
      "0.9210019267822736\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.87      0.81       102\n",
      "           1       1.00      0.10      0.17        21\n",
      "           2       0.97      0.99      0.98       371\n",
      "           3       1.00      0.80      0.89        25\n",
      "\n",
      "   micro avg       0.92      0.92      0.92       519\n",
      "   macro avg       0.93      0.69      0.71       519\n",
      "weighted avg       0.93      0.92      0.91       519\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score,classification_report\n",
    "#confusion matrix\n",
    "print(confusion_matrix(Y_test,Y_pred))\n",
    "print(accuracy_score(Y_test,Y_pred))\n",
    "print(classification_report(Y_test,Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
